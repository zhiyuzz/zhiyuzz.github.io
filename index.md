---
permalink: /
layout: default
---

Hello! I'm a postdoc at Harvard University, hosted by [Heng Yang](https://hankyang.seas.harvard.edu/). Previously I did my phd at Boston University, under the amazing guidance of [Yannis Paschalidis](https://sites.bu.edu/paschalidis/people/yannis-paschalidis/) and [Ashok Cutkosky](https://ashok.cutkosky.com/). Long ago I did my undergrad at Tsinghua University.

I'm broadly interested in the **foundation of data science**. Specifically, my research centers around **adaptive online learning**, which concerns the theory and practice of sequential decision making with Bayesian-type prior knowledge.

On the application side, I'm excited about various aspects of **robotics and automation**, especially algorithmic approaches that efficiently utilize large-scale pretraining (e.g., continual fine-tuning and conformal prediction). 

Email address: zhiyuz [at] seas (dot) harvard (dot) edu

[CV](https://zhiyuzz.github.io/CV_Zhiyu_Zhang.pdf){:target="_blank"}&nbsp;&nbsp; [Github](https://github.com/zhiyuzz)&nbsp;&nbsp; [Google Scholar](https://scholar.google.com/citations?hl=en&user=5KHfVTQAAAAJ&view_op=list_works&authuser=2&sortby=pubdate)

## Publication

Five representative works

 - [The Benefit of Being Bayesian in Online Conformal Prediction](https://arxiv.org/abs/2410.02561)<br>
ZZ, Zhou Lu, Heng Yang.<br>
Preprint.

 - [Fast TRAC: A Parameter-Free Optimizer for Lifelong Reinforcement Learning](https://arxiv.org/abs/2405.16642)<br>
Aneesh Muppidi, ZZ, Heng Yang.<br>
NeurIPS 2024.

 - [Improving Adaptive Online Learning Using Refined Discretization](https://arxiv.org/abs/2309.16044)<br>
ZZ, Heng Yang, Ashok Cutkosky, Ioannis Paschalidis.<br>
ALT 2024.

 - [Unconstrained Dynamic Regret via Sparse Coding](https://arxiv.org/abs/2301.13349)<br>
ZZ, Ashok Cutkosky, Ioannis Paschalidis.<br>
NeurIPS 2023.

 - [Optimal Comparator Adaptive Online Learning with Switching Cost](https://arxiv.org/abs/2205.06846)<br>
ZZ, Ashok Cutkosky, Ioannis Paschalidis.<br>
NeurIPS 2022. Also presented at ICML 2022 workshop. 

Other works

 - [Sparsity-Based Interpolation of External, Internal and Swap Regret](https://zhiyuzz.github.io/Adaptive_phi_regret.pdf){:target="_blank"}<br>
Zhou Lu, Y. Jennifer Sun, ZZ. (alphabetical order)<br>
Preprint.

 - [Adapting Conformal Prediction to Distribution Shifts Without Labels](https://arxiv.org/abs/2406.01416)<br>
Kevin Kasa, ZZ, Heng Yang, Graham Taylor.<br>
Preprint.

 - [Discounted Adaptive Online Learning: Towards Better Regularization](https://arxiv.org/abs/2402.02720)<br>
ZZ, David Bombara, Heng Yang.<br>
ICML 2024.

 - [Understanding Adam Optimizer via Online Learning of Updates: Adam is FTRL in Disguise](https://arxiv.org/abs/2402.01567)<br>
Kwangjun Ahn, ZZ, Yunbum Kook, Yan Dai.<br>
ICML 2024.

 - [PDE-Based Optimal Strategy for Unconstrained Online Learning](https://arxiv.org/abs/2201.07877)<br>
ZZ, Ashok Cutkosky, Ioannis Paschalidis.<br>
ICML 2022.

- [Adversarial Tracking Control via Strongly Adaptive Online Learning with Memory](https://arxiv.org/abs/2102.01623)<br>
ZZ, Ashok Cutkosky, Ioannis Paschalidis.<br>
AISTATS 2022.

- [Provable Hierarchical Imitation Learning via EM](https://arxiv.org/abs/2010.03133)<br>
ZZ, Ioannis Paschalidis.<br>
AISTATS 2021. Also presented at ICML 2020 Workshop.

PhD Dissertation.&nbsp; [Temporal Aspects of Adaptive Online Learning: Continuity and Representation](https://zhiyuzz.github.io/Dissertation_Zhiyu.pdf){:target="_blank"}
