---
permalink: /
layout: default
---

Hello! I'm a postdoc at Harvard University, hosted by Prof. [Heng Yang](https://hankyang.seas.harvard.edu/). Previously, I had a blast doing my phd at Boston University, advised by Prof. [Yannis Paschalidis](https://sites.bu.edu/paschalidis/people/yannis-paschalidis/) and Prof. [Ashok Cutkosky](https://ashok.cutkosky.com/). Long ago I did my undergrad at Tsinghua University.

I'm broadly interested in **sequential data science**. How do we process information revealed on a data stream, and rigorously use that to support real-time decision making? For me, this is a fascinating field at the intersection of optimization, signal processing, statistics and game theory. 

Specifically, my research centers around **adaptive online learning**. The goal is to design online decision making algorithms that Bayes-optimally exploit offline knowledge, such as domain structures, physical models and deep learning. I envision it as a bridge between offline methods and their robust online deployment against uncertainties. 

Recently I'm also excited about bringing such algorithmic advances closer to the real world, particularly in the area of **robotics and automation**. 

Email address: zhiyuz [at] seas (dot) harvard (dot) edu

[CV](https://zhiyuzz.github.io/CV_Zhiyu_Zhang.pdf){:target="_blank"}&nbsp;&nbsp; [Github](https://github.com/zhiyuzz)&nbsp;&nbsp; [Google Scholar](https://scholar.google.com/citations?hl=en&user=5KHfVTQAAAAJ&view_op=list_works&authuser=2&sortby=pubdate)&nbsp;&nbsp; [Semantic Scholar](https://www.semanticscholar.org/author/Zhiyu-Zhang/2117992745)

## Publication

 - [Discounted Adaptive Online Prediction](https://arxiv.org/abs/2402.02720)<br>
ZZ, David Bombara, Heng Yang.<br>
arXiv preprint.

 - [Understanding Adam Optimizer via Online Learning of Updates: Adam is FTRL in Disguise](https://arxiv.org/abs/2402.01567)<br>
Kwangjun Ahn, ZZ, Yunbum Kook, Yan Dai.<br>
arXiv preprint.

 - [Improving Adaptive Online Learning Using Refined Discretization](https://arxiv.org/abs/2309.16044)<br>
ZZ, Heng Yang, Ashok Cutkosky, Ioannis Paschalidis.<br>
ALT 2024.

 - [Unconstrained Dynamic Regret via Sparse Coding](https://arxiv.org/abs/2301.13349)<br>
ZZ, Ashok Cutkosky, Ioannis Paschalidis.<br>
NeurIPS 2023.

 - [Optimal Comparator Adaptive Online Learning with Switching Cost](https://arxiv.org/abs/2205.06846)<br>
ZZ, Ashok Cutkosky, Ioannis Paschalidis.<br>
NeurIPS 2022. Also presented at ICML 2022 workshop. 

 - [PDE-Based Optimal Strategy for Unconstrained Online Learning](https://arxiv.org/abs/2201.07877)<br>
ZZ, Ashok Cutkosky, Ioannis Paschalidis.<br>
ICML 2022.

- [Adversarial Tracking Control via Strongly Adaptive Online Learning with Memory](https://arxiv.org/abs/2102.01623)<br>
ZZ, Ashok Cutkosky, Ioannis Paschalidis.<br>
AISTATS 2022.

- [Provable Hierarchical Imitation Learning via EM](https://arxiv.org/abs/2010.03133)<br>
ZZ, Ioannis Paschalidis.<br>
AISTATS 2021. Also presented at ICML 2020 Workshop.

PhD Dissertation.&nbsp; [Temporal Aspects of Adaptive Online Learning: Continuity and Representation](https://zhiyuzz.github.io/Dissertation_Zhiyu.pdf){:target="_blank"}
